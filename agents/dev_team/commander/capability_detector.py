"""
æ¨¡å‹èƒ½åŠ›æ¢æµ‹ç³»ç»Ÿ

ç”¨äºè¯„ä¼°LLMåœ¨ä¸åŒç»´åº¦çš„èƒ½åŠ›è¾¹ç•Œï¼Œç”Ÿæˆèƒ½åŠ›æ¡£æ¡ˆç”¨äºæ™ºèƒ½ä»»åŠ¡åˆ†é…ã€‚
"""

from dataclasses import dataclass, field
from typing import Dict, List, Any, Optional, Tuple
from langchain_core.language_models import BaseChatModel
import time
import logging

logger = logging.getLogger(__name__)


@dataclass
class CapabilityProfile:
    """æ¨¡å‹èƒ½åŠ›æ¡£æ¡ˆ"""
    
    model_id: str
    scores: Dict[str, float] = field(default_factory=dict)
    strengths: List[str] = field(default_factory=list)
    weaknesses: List[str] = field(default_factory=list)
    optimal_temp: float = 0.7
    response_time: float = 0.0
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def get_score(self, category: str) -> float:
        """è·å–æŒ‡å®šç±»åˆ«çš„å¾—åˆ†"""
        return self.scores.get(category, 0.0)
    
    def is_strong_in(self, category: str, threshold: float = 0.7) -> bool:
        """åˆ¤æ–­æ˜¯å¦åœ¨æŸä¸ªé¢†åŸŸå…·æœ‰ä¼˜åŠ¿"""
        return self.get_score(category) >= threshold
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            "model_id": self.model_id,
            "scores": self.scores,
            "strengths": self.strengths,
            "weaknesses": self.weaknesses,
            "optimal_temp": self.optimal_temp,
            "response_time": self.response_time,
            "metadata": self.metadata,
        }


class CapabilityDetector:
    """
    æ¨¡å‹æ™ºåŠ›è¾¹ç•Œæ¢æµ‹å™¨
    
    è¯„ä¼°ç»´åº¦ï¼š
    1. é€»è¾‘æ¨ç† (logic)
    2. åˆ›æ„ç”Ÿæˆ (creativity)
    3. ä»£ç èƒ½åŠ› (code)
    4. æ•°æ®åˆ†æ (analysis)
    5. æ²Ÿé€šèƒ½åŠ› (communication)
    """
    
    # æµ‹è¯•é›†ï¼šç®€åŒ–ç‰ˆï¼ŒåæœŸå¯æ‰©å±•ä¸ºå®Œæ•´benchmark
    TEST_SUITE = {
        "logic": [
            {
                "question": "å¦‚æœæ‰€æœ‰Aéƒ½æ˜¯Bï¼Œæ‰€æœ‰Béƒ½æ˜¯Cï¼Œé‚£ä¹ˆæ‰€æœ‰Aéƒ½æ˜¯Cå—ï¼Ÿ",
                "expected_keywords": ["æ˜¯", "æ­£ç¡®", "å¯¹", "æ¼”ç»", "ä¸‰æ®µè®º"],
                "weight": 1.0,
            },
            {
                "question": "ä¸€ä¸ªæˆ¿é—´é‡Œæœ‰3ä¸ªå¼€å…³ï¼Œåˆ†åˆ«æ§åˆ¶å¦ä¸€ä¸ªæˆ¿é—´çš„3ä¸ªç¯æ³¡ã€‚ä½ åªèƒ½è¿›å…¥ç¯æ³¡æˆ¿é—´ä¸€æ¬¡ï¼Œå¦‚ä½•ç¡®å®šå“ªä¸ªå¼€å…³æ§åˆ¶å“ªä¸ªç¯æ³¡ï¼Ÿ",
                "expected_keywords": ["æ‰“å¼€", "å…³é—­", "çƒ­", "æ¸©åº¦", "æ—¶é—´"],
                "weight": 1.0,
            },
        ],
        "creativity": [
            {
                "question": "ç”¨'æ—¶é—´'ã€'é•œå­'ã€'å›å£°'ä¸‰ä¸ªè¯å†™ä¸€ä¸ªæœ‰è¶£çš„æ•…äº‹å¼€å¤´ï¼ˆ50å­—å†…ï¼‰",
                "expected_keywords": [],  # åˆ›æ„é¢˜æ— å›ºå®šç­”æ¡ˆï¼Œä¸»è¦çœ‹å¤šæ ·æ€§
                "weight": 1.0,
            },
            {
                "question": "ä¸ºä¸€å®¶AIåˆ›ä¸šå…¬å¸è®¾è®¡ä¸€ä¸ªç‹¬ç‰¹çš„logoæ¦‚å¿µ",
                "expected_keywords": ["ç¥ç»ç½‘ç»œ", "æœªæ¥", "æ™ºèƒ½", "åˆ›æ–°"],
                "weight": 1.0,
            },
        ],
        "code": [
            {
                "question": "å†™ä¸€ä¸ªPythonå‡½æ•°åˆ¤æ–­å­—ç¬¦ä¸²æ˜¯å¦ä¸ºå›æ–‡",
                "expected_keywords": ["def", "return", "==", "[::-1]", "reverse"],
                "weight": 1.0,
            },
            {
                "question": "è§£é‡ŠPythonä¸­çš„è£…é¥°å™¨æ˜¯ä»€ä¹ˆï¼Œå¹¶ä¸¾ä¾‹è¯´æ˜",
                "expected_keywords": ["@", "wrapper", "å‡½æ•°", "é—­åŒ…", "è¯­æ³•ç³–"],
                "weight": 1.0,
            },
        ],
        "analysis": [
            {
                "question": "ç»™å®šæ•°æ®ï¼š[10, 20, 15, 30, 25]ï¼Œè®¡ç®—å¹³å‡å€¼ã€ä¸­ä½æ•°ã€æ–¹å·®",
                "expected_keywords": ["20", "å¹³å‡", "ä¸­ä½æ•°", "æ–¹å·®", "æ ‡å‡†å·®"],
                "weight": 1.0,
            },
            {
                "question": "å¦‚æœä¸€å®¶å…¬å¸çš„æ”¶å…¥è¿ç»­3å¹´åˆ†åˆ«å¢é•¿10%ã€20%ã€-5%ï¼Œæ€»ä½“å¢é•¿ç‡æ˜¯å¤šå°‘ï¼Ÿ",
                "expected_keywords": ["23", "å¤åˆ", "å¢é•¿ç‡", "ç´¯ç§¯"],
                "weight": 1.0,
            },
        ],
        "communication": [
            {
                "question": "å‘éæŠ€æœ¯äººå‘˜è§£é‡Šä»€ä¹ˆæ˜¯'äº‘è®¡ç®—'",
                "expected_keywords": ["äº’è”ç½‘", "æœåŠ¡å™¨", "å­˜å‚¨", "ç§Ÿç”¨", "ç®€å•"],
                "weight": 1.0,
            },
            {
                "question": "ç”¨ä¸€å¥è¯æ€»ç»“æœºå™¨å­¦ä¹ çš„æ ¸å¿ƒæ€æƒ³",
                "expected_keywords": ["æ•°æ®", "å­¦ä¹ ", "æ¨¡å¼", "é¢„æµ‹", "ç»éªŒ"],
                "weight": 1.0,
            },
        ],
    }
    
    # èƒ½åŠ›é˜ˆå€¼é…ç½®
    STRENGTH_THRESHOLD = 0.7
    WEAKNESS_THRESHOLD = 0.4
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """
        åˆå§‹åŒ–æ¢æµ‹å™¨
        
        Args:
            config: é…ç½®å­—å…¸ï¼Œå¯åŒ…å«è‡ªå®šä¹‰æµ‹è¯•é›†ã€é˜ˆå€¼ç­‰
        """
        self.config = config or {}
        self.test_suite = self.config.get("test_suite", self.TEST_SUITE)
        self.strength_threshold = self.config.get("strength_threshold", self.STRENGTH_THRESHOLD)
        self.weakness_threshold = self.config.get("weakness_threshold", self.WEAKNESS_THRESHOLD)
    
    def detect(self, model: BaseChatModel, model_id: str = "unknown") -> CapabilityProfile:
        """
        æ‰§è¡Œå®Œæ•´èƒ½åŠ›æ¢æµ‹
        
        Args:
            model: å¾…æµ‹è¯•çš„LLMæ¨¡å‹
            model_id: æ¨¡å‹æ ‡è¯†ç¬¦
            
        Returns:
            CapabilityProfile: èƒ½åŠ›æ¡£æ¡ˆ
        """
        print(f"\nğŸ” å¼€å§‹æ¢æµ‹æ¨¡å‹èƒ½åŠ›: {model_id}")
        
        scores = {}
        total_time = 0.0
        
        for category, tests in self.test_suite.items():
            print(f"  ğŸ“Š æµ‹è¯•ç±»åˆ«: {category}")
            category_score, avg_time = self._run_tests(model, tests)
            scores[category] = category_score
            total_time += avg_time
            print(f"    â””â”€ å¾—åˆ†: {category_score:.2f}, å¹³å‡å“åº”æ—¶é—´: {avg_time:.2f}s")
        
        # è¯†åˆ«ä¼˜åŠ¿å’ŒåŠ£åŠ¿
        strengths = self._identify_strengths(scores)
        weaknesses = self._identify_weaknesses(scores)
        
        # å¯»æ‰¾æœ€ä¼˜temperatureï¼ˆç®€åŒ–ç‰ˆï¼šåŸºäºå½“å‰é…ç½®ï¼‰
        optimal_temp = self._find_optimal_temp(model, scores)
        
        # è®¡ç®—å¹³å‡å“åº”æ—¶é—´
        avg_response_time = total_time / len(self.test_suite) if self.test_suite else 0.0
        
        profile = CapabilityProfile(
            model_id=model_id,
            scores=scores,
            strengths=strengths,
            weaknesses=weaknesses,
            optimal_temp=optimal_temp,
            response_time=avg_response_time,
            metadata={"test_count": sum(len(tests) for tests in self.test_suite.values())}
        )
        
        print(f"\nâœ… æ¢æµ‹å®Œæˆ!")
        print(f"  ä¼˜åŠ¿é¢†åŸŸ: {', '.join(strengths) if strengths else 'æ— æ˜¾è‘—ä¼˜åŠ¿'}")
        print(f"  åŠ£åŠ¿é¢†åŸŸ: {', '.join(weaknesses) if weaknesses else 'æ— æ˜¾è‘—åŠ£åŠ¿'}")
        print(f"  æ¨ètemperature: {optimal_temp}")
        
        return profile
    
    def _run_tests(self, model: BaseChatModel, tests: List[Dict[str, Any]]) -> Tuple[float, float]:
        """
        è¿è¡Œä¸€ç»„æµ‹è¯•
        
        Args:
            model: LLMæ¨¡å‹
            tests: æµ‹è¯•åˆ—è¡¨
            
        Returns:
            (å¹³å‡å¾—åˆ†, å¹³å‡å“åº”æ—¶é—´)
        """
        total_score = 0.0
        total_time = 0.0
        
        for idx, test in enumerate(tests, 1):
            start_time = time.time()
            
            try:
                # è°ƒç”¨æ¨¡å‹
                response = model.invoke(test["question"])
                response_text = response.content if hasattr(response, 'content') else str(response)
                
                # è®¡ç®—å¾—åˆ†
                score = self._score_response(response_text, test)
                total_score += score * test.get("weight", 1.0)
                
                logger.debug(f"æµ‹è¯• {idx}/{len(tests)} å®Œæˆï¼Œå¾—åˆ†: {score:.2f}")
                
            except Exception as e:
                logger.warning(f"æµ‹è¯• {idx}/{len(tests)} å¤±è´¥: {str(e)}")
                print(f"    âš ï¸ æµ‹è¯•å¤±è´¥: {str(e)}")
                total_score += 0.0
            
            elapsed = time.time() - start_time
            total_time += elapsed
        
        avg_score = total_score / len(tests) if tests else 0.0
        avg_time = total_time / len(tests) if tests else 0.0
        
        return avg_score, avg_time
    
    def _score_response(self, response: str, test: Dict[str, Any]) -> float:
        """
        è¯„ä¼°å›ç­”è´¨é‡
        
        ç®€åŒ–ç‰ˆï¼šåŸºäºå…³é”®è¯åŒ¹é…ã€‚åæœŸå¯æ‰©å±•ä¸ºLLM-as-judgeæˆ–è§„åˆ™å¼•æ“
        
        Args:
            response: æ¨¡å‹å›ç­”
            test: æµ‹è¯•é…ç½®
            
        Returns:
            å¾—åˆ† (0.0-1.0)
        """
        keywords = test.get("expected_keywords", [])
        
        if not keywords:
            # åˆ›æ„é¢˜ç­‰æ— å…³é”®è¯çš„ï¼Œç®€å•åŸºäºé•¿åº¦å’Œç»“æ„åˆ¤æ–­
            if len(response) > 20 and len(response) < 500:
                return 0.7  # åŸºç¡€åˆ†
            return 0.5
        
        # å…³é”®è¯åŒ¹é…
        response_lower = response.lower()
        matched = sum(1 for kw in keywords if kw.lower() in response_lower)
        
        # è®¡ç®—å¾—åˆ†ï¼šåŒ¹é…ç‡ + é•¿åº¦å¥–åŠ±
        match_ratio = matched / len(keywords) if keywords else 0.0
        length_bonus = 0.1 if 50 < len(response) < 1000 else 0.0
        
        return min(match_ratio + length_bonus, 1.0)
    
    def _identify_strengths(self, scores: Dict[str, float]) -> List[str]:
        """è¯†åˆ«ä¼˜åŠ¿é¢†åŸŸ"""
        return [
            category for category, score in scores.items()
            if score >= self.strength_threshold
        ]
    
    def _identify_weaknesses(self, scores: Dict[str, float]) -> List[str]:
        """è¯†åˆ«åŠ£åŠ¿é¢†åŸŸ"""
        return [
            category for category, score in scores.items()
            if score < self.weakness_threshold
        ]
    
    def _find_optimal_temp(self, model: BaseChatModel, scores: Dict[str, float]) -> float:
        """
        å¯»æ‰¾æœ€ä¼˜temperature
        
        ç®€åŒ–ç‰ˆï¼šåŸºäºèƒ½åŠ›æ¡£æ¡ˆæ¨è
        - é€»è¾‘/ä»£ç èƒ½åŠ›å¼º -> ä½temperature (0.3)
        - åˆ›æ„èƒ½åŠ›å¼º -> é«˜temperature (0.8)
        - å‡è¡¡ -> ä¸­ç­‰temperature (0.5)
        
        Args:
            model: LLMæ¨¡å‹
            scores: èƒ½åŠ›å¾—åˆ†
            
        Returns:
            æ¨èçš„temperatureå€¼
        """
        logic_score = scores.get("logic", 0.0)
        code_score = scores.get("code", 0.0)
        creativity_score = scores.get("creativity", 0.0)
        
        # åŠ æƒè®¡ç®—
        analytical_weight = (logic_score + code_score) / 2
        creative_weight = creativity_score
        
        if analytical_weight > creative_weight + 0.2:
            return 0.3  # ååˆ†æå‹ä»»åŠ¡
        elif creative_weight > analytical_weight + 0.2:
            return 0.8  # ååˆ›æ„å‹ä»»åŠ¡
        else:
            return 0.5  # å‡è¡¡å‹
    
    def quick_detect(self, model_id: str, model_config: Dict[str, Any]) -> CapabilityProfile:
        """
        å¿«é€Ÿæ¢æµ‹ï¼ˆåŸºäºç¡¬ç¼–ç è§„åˆ™ï¼Œæ— éœ€å®é™…è°ƒç”¨æ¨¡å‹ï¼‰
        
        é€‚ç”¨åœºæ™¯ï¼š
        - å·²çŸ¥æ¨¡å‹ç‰¹æ€§
        - éœ€è¦å¿«é€Ÿåˆå§‹åŒ–
        - èŠ‚çœAPIæˆæœ¬
        
        Args:
            model_id: æ¨¡å‹æ ‡è¯†
            model_config: æ¨¡å‹é…ç½®
            
        Returns:
            CapabilityProfile: åŸºäºè§„åˆ™çš„èƒ½åŠ›æ¡£æ¡ˆ
        """
        logger.info(f"å¿«é€Ÿæ¢æµ‹æ¨¡å¼: {model_id}")
        print(f"\nâš¡ å¿«é€Ÿæ¢æµ‹æ¨¡å¼: {model_id}")
        
        # æ‰©å±•çš„æ¨¡å‹èƒ½åŠ›æ¡£æ¡ˆåº“
        profiles = {
            "gpt-4o": {
                "scores": {"logic": 0.92, "creativity": 0.88, "code": 0.93, "analysis": 0.90, "communication": 0.92},
                "optimal_temp": 0.7,
            },
            "gpt-4": {
                "scores": {"logic": 0.9, "creativity": 0.85, "code": 0.9, "analysis": 0.85, "communication": 0.9},
                "optimal_temp": 0.7,
            },
            "gpt-3.5-turbo": {
                "scores": {"logic": 0.75, "creativity": 0.7, "code": 0.75, "analysis": 0.7, "communication": 0.8},
                "optimal_temp": 0.7,
            },
            "claude-3-opus": {
                "scores": {"logic": 0.90, "creativity": 0.93, "code": 0.88, "analysis": 0.85, "communication": 0.95},
                "optimal_temp": 0.7,
            },
            "claude-3-sonnet": {
                "scores": {"logic": 0.85, "creativity": 0.88, "code": 0.83, "analysis": 0.80, "communication": 0.90},
                "optimal_temp": 0.7,
            },
            "claude-3": {
                "scores": {"logic": 0.85, "creativity": 0.9, "code": 0.85, "analysis": 0.8, "communication": 0.95},
                "optimal_temp": 0.7,
            },
            "gemini-pro": {
                "scores": {"logic": 0.82, "creativity": 0.80, "code": 0.81, "analysis": 0.83, "communication": 0.85},
                "optimal_temp": 0.7,
            },
            "deepseek-chat": {
                "scores": {"logic": 0.84, "creativity": 0.78, "code": 0.85, "analysis": 0.83, "communication": 0.82},
                "optimal_temp": 0.7,
            },
            "deepseek-reasoner": {
                "scores": {"logic": 0.90, "creativity": 0.72, "code": 0.88, "analysis": 0.91, "communication": 0.80},
                "optimal_temp": 0.6,
            },
            "grok-4.1-fast": {
                "scores": {"logic": 0.86, "creativity": 0.85, "code": 0.86, "analysis": 0.84, "communication": 0.86},
                "optimal_temp": 0.7,
            },
        }
        
        # æ¨¡ç³ŠåŒ¹é…ï¼ˆä¼˜å…ˆåŒ¹é…æ›´å…·ä½“çš„æ¨¡å‹åï¼‰
        matched_profile = None
        matched_key = None
        best_match_length = 0
        
        for key, profile_data in profiles.items():
            if key in model_id.lower():
                # é€‰æ‹©æœ€é•¿åŒ¹é…ï¼ˆæ›´å…·ä½“ï¼‰
                if len(key) > best_match_length:
                    matched_profile = profile_data
                    matched_key = key
                    best_match_length = len(key)
        
        # é»˜è®¤é…ç½®
        if not matched_profile:
            logger.warning(f"æœªè¯†åˆ«æ¨¡å‹ '{model_id}'ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            matched_profile = {
                "scores": {"logic": 0.6, "creativity": 0.6, "code": 0.6, "analysis": 0.6, "communication": 0.6},
                "optimal_temp": 0.7,
            }
            print(f"  âš ï¸ æœªè¯†åˆ«æ¨¡å‹ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        else:
            logger.info(f"åŒ¹é…åˆ°æ¨¡å‹æ¡£æ¡ˆ: {matched_key}")
        
        scores = matched_profile["scores"]
        strengths = self._identify_strengths(scores)
        weaknesses = self._identify_weaknesses(scores)
        
        profile = CapabilityProfile(
            model_id=model_id,
            scores=scores,
            strengths=strengths,
            weaknesses=weaknesses,
            optimal_temp=matched_profile["optimal_temp"],
            response_time=0.0,
            metadata={
                "mode": "quick_detect", 
                "config": model_config,
                "matched_template": matched_key if matched_key else "default"
            }
        )
        
        logger.info(f"å¿«é€Ÿæ¢æµ‹å®Œæˆ - ä¼˜åŠ¿: {strengths}, åŠ£åŠ¿: {weaknesses}")
        print(f"  âœ… å¿«é€Ÿæ¢æµ‹å®Œæˆ (ä¼˜åŠ¿: {', '.join(strengths) if strengths else 'æ— '})")
        return profile
