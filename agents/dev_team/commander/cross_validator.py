"""
äº¤å‰æ ¸æŸ¥æ¡†æ¶

å®ç°Agentäº’æ£€ã€ç»“æœæ ¡éªŒå’Œä¸€è‡´æ€§åˆ†æã€‚
"""

from dataclasses import dataclass, field
from typing import Dict, List, Any, Optional, Set
import json
from difflib import SequenceMatcher


@dataclass
class Review:
    """å®¡æŸ¥æ„è§"""
    reviewer: str
    target: str
    score: float  # 0.0-1.0
    issues: List[str] = field(default_factory=list)
    suggestions: List[str] = field(default_factory=list)
    confidence: float = 0.7
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class Conflict:
    """å†²çªä¿¡æ¯"""
    agents: List[str]
    point: str
    descriptions: List[str]
    severity: str = "medium"  # low/medium/high
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class ValidationReport:
    """æ ¡éªŒæŠ¥å‘Š"""
    status: str  # consistent/conflict_found/conflict_resolved
    reviews: List[Review] = field(default_factory=list)
    conflicts: List[Conflict] = field(default_factory=list)
    consistency_score: float = 0.0
    resolution: Optional[str] = None
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "status": self.status,
            "reviews_count": len(self.reviews),
            "conflicts_count": len(self.conflicts),
            "consistency_score": self.consistency_score,
            "resolution": self.resolution,
            "metadata": self.metadata,
        }


class CrossValidator:
    """
    Agentäº’æ£€ä¸ç»“æœæ ¡éªŒå™¨
    
    åŠŸèƒ½ï¼š
    1. åŒ¿åäº¤å‰å®¡æŸ¥
    2. å·®å¼‚è¯†åˆ«
    3. å†²çªè§£å†³
    4. ä¸€è‡´æ€§è¯„åˆ†
    """
    
    # é…ç½®å‚æ•°
    CONSISTENCY_THRESHOLD = 0.8
    CONFLICT_SEVERITY_THRESHOLDS = {
        "low": 0.3,
        "medium": 0.6,
        "high": 0.9
    }
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """
        åˆå§‹åŒ–äº¤å‰æ ¡éªŒå™¨
        
        Args:
            config: é…ç½®å­—å…¸
        """
        self.config = config or {}
        self.consistency_threshold = self.config.get(
            "consistency_threshold", 
            self.CONSISTENCY_THRESHOLD
        )
        self.error_knowledge_base: Set[str] = set()  # å…¨å±€é”™è¯¯çŸ¥è¯†åº“
    
    def validate(
        self,
        results: Dict[str, Any],
        agents: List[Any],
        anonymous: bool = True
    ) -> ValidationReport:
        """
        äº¤å‰æ ¸æŸ¥æµç¨‹
        
        Args:
            results: Agentè¾“å‡ºç»“æœå­—å…¸ {agent_name: output}
            agents: Agentåˆ—è¡¨
            anonymous: æ˜¯å¦åŒ¿åå®¡æŸ¥
            
        Returns:
            ValidationReport: æ ¡éªŒæŠ¥å‘Š
        """
        print(f"\nğŸ” å¯åŠ¨äº¤å‰æ ¸æŸ¥ (åŒ¿åæ¨¡å¼: {anonymous})...")
        print(f"  å¾…æ ¡éªŒç»“æœæ•°: {len(results)}")
        
        # 1. æ”¶é›†æ‰€æœ‰Agentçš„å®¡æŸ¥æ„è§
        reviews = self._collect_reviews(results, agents, anonymous)
        
        # 2. åˆ†æå·®å¼‚å’Œå†²çª
        conflicts = self._identify_conflicts(reviews, results)
        
        # 3. è®¡ç®—ä¸€è‡´æ€§å¾—åˆ†
        consistency_score = self._calculate_consistency(reviews, conflicts)
        
        # 4. å¤„ç†å†²çª
        if conflicts:
            print(f"  âš ï¸ å‘ç° {len(conflicts)} ä¸ªå†²çª")
            resolution = self._resolve_conflicts(conflicts, results, agents)
            status = "conflict_resolved"
        else:
            print(f"  âœ… æ‰€æœ‰ç»“æœä¸€è‡´")
            resolution = None
            status = "consistent"
        
        # 5. æ›´æ–°é”™è¯¯çŸ¥è¯†åº“
        self._update_error_knowledge(conflicts)
        
        report = ValidationReport(
            status=status,
            reviews=reviews,
            conflicts=conflicts,
            consistency_score=consistency_score,
            resolution=resolution,
            metadata={
                "anonymous": anonymous,
                "agents_count": len(agents),
                "error_kb_size": len(self.error_knowledge_base)
            }
        )
        
        print(f"  ğŸ“Š ä¸€è‡´æ€§å¾—åˆ†: {consistency_score:.2f}")
        return report
    
    def _collect_reviews(
        self,
        results: Dict[str, Any],
        agents: List[Any],
        anonymous: bool
    ) -> List[Review]:
        """
        æ”¶é›†å®¡æŸ¥æ„è§
        
        æ¯ä¸ªAgentå®¡æŸ¥å…¶ä»–Agentçš„è¾“å‡º
        """
        print("  ğŸ“ æ”¶é›†å®¡æŸ¥æ„è§...")
        reviews = []
        
        # åˆ›å»ºåŒ¿åæ˜ å°„
        agent_names = list(results.keys())
        if anonymous:
            # æ‰“ä¹±é¡ºåºå®ç°åŒ¿å
            import random
            review_assignments = agent_names.copy()
            random.shuffle(review_assignments)
        else:
            review_assignments = agent_names
        
        # æ¯ä¸ªAgentå®¡æŸ¥ä¸‹ä¸€ä¸ªAgentçš„ç»“æœ
        for i, reviewer_name in enumerate(agent_names):
            target_idx = (i + 1) % len(agent_names)
            target_name = review_assignments[target_idx]
            
            if target_name == reviewer_name:
                continue  # è·³è¿‡è‡ªå·±
            
            target_result = results.get(target_name, "")
            
            # æ‰§è¡Œå®¡æŸ¥ï¼ˆç®€åŒ–ç‰ˆï¼šåŸºäºè§„åˆ™ï¼‰
            review = self._perform_review(
                reviewer_name,
                target_name if not anonymous else f"Anonymous_{target_idx}",
                target_result
            )
            reviews.append(review)
        
        print(f"    â””â”€ æ”¶é›†åˆ° {len(reviews)} ä»½å®¡æŸ¥æ„è§")
        return reviews
    
    def _perform_review(
        self,
        reviewer: str,
        target: str,
        result: Any
    ) -> Review:
        """
        æ‰§è¡Œå•æ¬¡å®¡æŸ¥
        
        ç®€åŒ–ç‰ˆï¼šåŸºäºè§„åˆ™çš„å®¡æŸ¥
        å®é™…åº”è°ƒç”¨ LLM è¿›è¡Œæ·±åº¦åˆ†æ
        """
        result_str = str(result)
        issues = []
        suggestions = []
        score = 1.0
        
        # æ£€æŸ¥å¸¸è§é—®é¢˜
        if len(result_str) < 50:
            issues.append("è¾“å‡ºå†…å®¹è¿‡çŸ­ï¼Œå¯èƒ½ä¸å®Œæ•´")
            score -= 0.2
        
        if "error" in result_str.lower() or "é”™è¯¯" in result_str:
            issues.append("è¾“å‡ºä¸­åŒ…å«é”™è¯¯ä¿¡æ¯")
            score -= 0.3
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ä»£ç å—
        if "<file" not in result_str and "def " not in result_str:
            suggestions.append("å»ºè®®åŒ…å«å…·ä½“ä»£ç å®ç°")
            score -= 0.1
        
        # æ£€æŸ¥é”™è¯¯çŸ¥è¯†åº“
        for known_error in self.error_knowledge_base:
            if known_error in result_str:
                issues.append(f"æ£€æµ‹åˆ°å·²çŸ¥é”™è¯¯æ¨¡å¼: {known_error[:50]}...")
                score -= 0.2
                break
        
        score = max(0.0, min(score, 1.0))
        
        return Review(
            reviewer=reviewer,
            target=target,
            score=score,
            issues=issues,
            suggestions=suggestions,
            confidence=0.7
        )
    
    def _identify_conflicts(
        self,
        reviews: List[Review],
        results: Dict[str, Any]
    ) -> List[Conflict]:
        """
        è¯†åˆ«å†²çª
        
        åŸºäºå®¡æŸ¥æ„è§å’Œç»“æœå·®å¼‚
        """
        print("  ğŸ” è¯†åˆ«å†²çª...")
        conflicts = []
        
        # 1. åŸºäºå®¡æŸ¥åˆ†æ•°çš„å†²çª
        low_score_reviews = [r for r in reviews if r.score < 0.5]
        if low_score_reviews:
            for review in low_score_reviews:
                conflict = Conflict(
                    agents=[review.reviewer, review.target],
                    point="ä½è´¨é‡è¾“å‡º",
                    descriptions=[f"{review.reviewer} è®¤ä¸º {review.target} çš„è¾“å‡ºè´¨é‡ä¸ä½³ (å¾—åˆ†: {review.score:.2f})"],
                    severity=self._determine_severity(review.score),
                    metadata={"issues": review.issues}
                )
                conflicts.append(conflict)
        
        # 2. åŸºäºç»“æœç›¸ä¼¼åº¦çš„å†²çª
        result_items = list(results.items())
        for i in range(len(result_items)):
            for j in range(i + 1, len(result_items)):
                name1, result1 = result_items[i]
                name2, result2 = result_items[j]
                
                similarity = self._calculate_similarity(str(result1), str(result2))
                
                # å¦‚æœç»“æœå·®å¼‚è¿‡å¤§ï¼Œå¯èƒ½å­˜åœ¨å†²çª
                if similarity < 0.3:
                    conflict = Conflict(
                        agents=[name1, name2],
                        point="ç»“æœå·®å¼‚æ˜¾è‘—",
                        descriptions=[
                            f"{name1} å’Œ {name2} çš„è¾“å‡ºç›¸ä¼¼åº¦ä»…ä¸º {similarity:.2f}",
                            "å¯èƒ½å­˜åœ¨ç†è§£åå·®æˆ–å®ç°åˆ†æ­§"
                        ],
                        severity="medium",
                        metadata={"similarity": similarity}
                    )
                    conflicts.append(conflict)
        
        return conflicts
    
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """
        è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦
        
        ä½¿ç”¨SequenceMatcherç®—æ³•
        """
        return SequenceMatcher(None, text1, text2).ratio()
    
    def _determine_severity(self, score: float) -> str:
        """ç¡®å®šå†²çªä¸¥é‡ç¨‹åº¦"""
        if score < 0.3:
            return "high"
        elif score < 0.6:
            return "medium"
        else:
            return "low"
    
    def _calculate_consistency(
        self,
        reviews: List[Review],
        conflicts: List[Conflict]
    ) -> float:
        """
        è®¡ç®—æ•´ä½“ä¸€è‡´æ€§å¾—åˆ†
        
        ç»¼åˆè€ƒè™‘å®¡æŸ¥åˆ†æ•°å’Œå†²çªæ•°é‡
        """
        if not reviews:
            return 0.0
        
        # å¹³å‡å®¡æŸ¥åˆ†æ•°
        avg_review_score = sum(r.score for r in reviews) / len(reviews)
        
        # å†²çªæƒ©ç½š
        conflict_penalty = len(conflicts) * 0.1
        
        consistency_score = max(0.0, avg_review_score - conflict_penalty)
        return consistency_score
    
    def _resolve_conflicts(
        self,
        conflicts: List[Conflict],
        results: Dict[str, Any],
        agents: List[Any]
    ) -> str:
        """
        è§£å†³å†²çª
        
        ç­–ç•¥ï¼š
        1. è¦æ±‚å†²çªæ–¹è‡ªè¯
        2. ç¬¬ä¸‰æ–¹ä»²è£
        3. é€‰æ‹©æœ€ä½³æ–¹æ¡ˆ
        """
        print("  âš–ï¸ è§£å†³å†²çª...")
        
        resolutions = []
        
        for conflict in conflicts:
            if conflict.severity == "high":
                # é«˜ä¼˜å…ˆçº§å†²çªï¼šéœ€è¦è¯¦ç»†åˆ†æ
                resolution = self._resolve_high_severity_conflict(conflict, results)
                resolutions.append(f"é«˜ä¸¥é‡åº¦å†²çª: {resolution}")
            else:
                # ä½/ä¸­ä¼˜å…ˆçº§ï¼šç®€å•å¤„ç†
                resolution = f"è®°å½•å†²çªç‚¹: {conflict.point}"
                resolutions.append(resolution)
        
        return "\n".join(resolutions)
    
    def _resolve_high_severity_conflict(
        self,
        conflict: Conflict,
        results: Dict[str, Any]
    ) -> str:
        """
        è§£å†³é«˜ä¸¥é‡åº¦å†²çª
        
        ç®€åŒ–ç‰ˆï¼šé€‰æ‹©è´¨é‡è¾ƒé«˜çš„ç»“æœ
        å®é™…åº”å¼•å…¥LLMè¿›è¡Œæ·±åº¦åˆ†æå’Œä»²è£
        """
        # è·å–å†²çªåŒæ–¹çš„ç»“æœ
        agent1, agent2 = conflict.agents[:2]
        result1 = results.get(agent1, "")
        result2 = results.get(agent2, "")
        
        # ç®€å•å¯å‘å¼ï¼šé€‰æ‹©æ›´é•¿çš„ï¼ˆé€šå¸¸æ›´è¯¦ç»†ï¼‰
        if len(str(result1)) > len(str(result2)):
            return f"é€‰æ‹© {agent1} çš„æ–¹æ¡ˆï¼ˆå†…å®¹æ›´è¯¦ç»†ï¼‰"
        else:
            return f"é€‰æ‹© {agent2} çš„æ–¹æ¡ˆï¼ˆå†…å®¹æ›´è¯¦ç»†ï¼‰"
    
    def _update_error_knowledge(self, conflicts: List[Conflict]):
        """
        æ›´æ–°å…¨å±€é”™è¯¯çŸ¥è¯†åº“
        
        è®°å½•å¸¸è§é”™è¯¯æ¨¡å¼ä»¥ä¾›æœªæ¥å‚è€ƒ
        """
        for conflict in conflicts:
            if conflict.severity == "high":
                # æå–é”™è¯¯æ¨¡å¼ï¼ˆç®€åŒ–ç‰ˆï¼‰
                error_pattern = f"{conflict.point}:{','.join(conflict.agents)}"
                self.error_knowledge_base.add(error_pattern)
    
    def get_error_knowledge(self) -> List[str]:
        """è·å–é”™è¯¯çŸ¥è¯†åº“å†…å®¹"""
        return list(self.error_knowledge_base)
    
    def add_error_pattern(self, pattern: str):
        """æ‰‹åŠ¨æ·»åŠ é”™è¯¯æ¨¡å¼åˆ°çŸ¥è¯†åº“"""
        self.error_knowledge_base.add(pattern)
    
    def quick_validate(
        self,
        results: Dict[str, Any],
        threshold: float = 0.8
    ) -> bool:
        """
        å¿«é€Ÿæ ¡éªŒ
        
        ä»…æ£€æŸ¥åŸºæœ¬ä¸€è‡´æ€§ï¼Œä¸è¿›è¡Œè¯¦ç»†å®¡æŸ¥
        
        Args:
            results: ç»“æœå­—å…¸
            threshold: ä¸€è‡´æ€§é˜ˆå€¼
            
        Returns:
            æ˜¯å¦é€šè¿‡æ ¡éªŒ
        """
        if len(results) < 2:
            return True
        
        # æ¯”è¾ƒæ‰€æœ‰ç»“æœçš„ç›¸ä¼¼åº¦
        result_values = list(results.values())
        similarities = []
        
        for i in range(len(result_values)):
            for j in range(i + 1, len(result_values)):
                sim = self._calculate_similarity(
                    str(result_values[i]),
                    str(result_values[j])
                )
                similarities.append(sim)
        
        avg_similarity = sum(similarities) / len(similarities) if similarities else 0.0
        return avg_similarity >= threshold
